{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cda4acfc-fe3c-4c9a-94fb-a16d31adbf7d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# 1D Multiexponential Decay fiting script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d66a829-2936-494a-9594-f774b1a91f26",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'channel_PSEN119_signal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01malvra_tools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchannels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01malvra_tools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01malvra_tools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mXAS_functions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01malvra_tools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mXAS_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msfdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SFScanInfo\n",
      "File \u001b[0;32m/das/work/p22/p22591/anaconda/alvra-analysis-p22591/lib/python3.12/site-packages/alvra_tools/XAS_functions.py:2370\u001b[0m\n\u001b[1;32m   2366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (DataFluo1_pump, DataFluo1_unpump, Pump_probe1, DataFluo2_pump, DataFluo2_unpump, Pump_probe2, Izero_pump, Izero_unpump, correlation1, correlation2, scanvar, goodshots1, goodshots2)\n\u001b[1;32m   2368\u001b[0m \u001b[38;5;66;03m######################################\u001b[39;00m\n\u001b[0;32m-> 2370\u001b[0m TT_PSEN119 \u001b[38;5;241m=\u001b[39m [\u001b[43mchannel_PSEN119_signal\u001b[49m, channel_PSEN119_bkg] \n\u001b[1;32m   2371\u001b[0m TT_PSEN124 \u001b[38;5;241m=\u001b[39m [channel_PSEN124_signal, channel_PSEN124_bkg, channel_PSEN124_arrTimes, channel_PSEN124_arrTimesAmp, channel_PSEN124_peaks, channel_PSEN124_edges]\n\u001b[1;32m   2372\u001b[0m TT_PSEN126 \u001b[38;5;241m=\u001b[39m [channel_PSEN126_signal, channel_PSEN126_bkg, channel_PSEN126_arrTimes, channel_PSEN126_arrTimesAmp, channel_PSEN126_peaks, channel_PSEN126_edges]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'channel_PSEN119_signal' is not defined"
     ]
    }
   ],
   "source": [
    "from alvra_tools.load_data import *\n",
    "from alvra_tools.channels import *\n",
    "from alvra_tools.utils import *\n",
    "from alvra_tools.XAS_functions import *\n",
    "from alvra_tools.XAS_utils import *\n",
    "from sfdata import SFScanInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97bed56-da33-4760-84bf-f0c48c214be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import special as _special\n",
    "from scipy.optimize import least_squares\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5658e662-0298-42cb-a582-a77e892742b0",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1836864-ff07-4ffa-a8b4-6d9a98393ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgroup = 'p22591'\n",
    "Loaddir_name = ''\n",
    "\n",
    "runlist = [89]\n",
    "#runlist = np.arange(205, 225)\n",
    "t0_offsets = [0]*len(runlist)\n",
    "#t0_offsets = [50, 20]\n",
    "\n",
    "##############################################\n",
    "Loaddir = '/sf/alvra/data/{}/work/Reduced_data/{}/'.format(pgroup, Loaddir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b74e4f5-d288-4448-bee1-c4a72dafee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot_correlations_scan(pgroup, Loaddir, runlist, path='work/TestData', timescan=True, lowlim = 0.95)\n",
    "#Plot_scan_2diodes(pgroup, Loaddir, runlist, path='work/TestData', timescan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42093440-7e4d-46d1-a317-10fba9527a1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pgroup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m withTT    \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m##############################################\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m Loaddir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/sf/alvra/data/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/work/Reduced_data/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43mpgroup\u001b[49m, Loaddir_name)\n\u001b[1;32m      5\u001b[0m firstrun \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/sf/alvra/data/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/raw/*\u001b[39m\u001b[38;5;132;01m{:04d}\u001b[39;00m\u001b[38;5;124m*/meta/scan.json\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(pgroup, runlist[\u001b[38;5;241m0\u001b[39m]))[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#firstrun = glob.glob('/sf/alvra/data/{}/work/TestData/*{:04d}*/meta/scan.json'.format(pgroup, runlist[0]))[0]\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pgroup' is not defined"
     ]
    }
   ],
   "source": [
    "withTT    = False\n",
    "\n",
    "##############################################\n",
    "Loaddir = '/sf/alvra/data/{}/work/Reduced_data/{}'.format(pgroup, Loaddir_name)\n",
    "firstrun = glob.glob('/sf/alvra/data/{}/raw/*{:04d}*/meta/scan.json'.format(pgroup, runlist[0]))[0]\n",
    "#firstrun = glob.glob('/sf/alvra/data/{}/work/TestData/*{:04d}*/meta/scan.json'.format(pgroup, runlist[0]))[0]\n",
    "\n",
    "from sfdata import SFScanInfo\n",
    "scan = SFScanInfo(firstrun)\n",
    "#acqlist = np.arange(1, len(scan.files))\n",
    "\n",
    "data1, titlestring_stack1 = load_reduced_data(pgroup, Loaddir, runlist, switch_diodes=False, t0_offset=t0_offsets)\n",
    "data2, titlestring_stack2 = load_reduced_data(pgroup, Loaddir, runlist, switch_diodes=True, t0_offset=t0_offsets)\n",
    "#Plot_reduced_data(data1, scan, titlestring_stack1, withTT)\n",
    "#Plot_reduced_data(data2, scan, titlestring_stack2, withTT)\n",
    "\n",
    "readbacks = np.asarray(data1['readbacks'], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "251e70c6-f7c1-4477-8aa0-e91d6adef18e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'readbacks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m min_delay \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m500\u001b[39m\n\u001b[1;32m      4\u001b[0m max_delay \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n\u001b[0;32m----> 6\u001b[0m n_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mreadbacks\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      7\u001b[0m (variable_bins, numbins)\u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m17\u001b[39m)\n\u001b[1;32m      8\u001b[0m thresh\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'readbacks' is not defined"
     ]
    }
   ],
   "source": [
    "quantile = 0.5\n",
    "binsize = 50\n",
    "min_delay = -500\n",
    "max_delay = 500\n",
    "\n",
    "n_points = len(readbacks[0])\n",
    "(variable_bins, numbins)= (True, 17)\n",
    "thresh=0\n",
    "n_sigma=5\n",
    "rawflag = True\n",
    "####################################################################\n",
    "####################################################################\n",
    "\n",
    "results1 = Rebin_and_filter_timescans(data1, binsize, min_delay, max_delay, quantile, withTT, thresh, n_sigma, rawflag, numbins, variable_bins)\n",
    "results2 = Rebin_and_filter_timescans(data2, binsize, min_delay, max_delay, quantile, withTT, thresh, n_sigma, rawflag, numbins, variable_bins)\n",
    "plot_bins_population(results2, titlestring_stack1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6ecc88b-b7bf-4ebf-ba93-bc7a202d402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kin(results,label):\n",
    "    pp_TT       = results['pp']      # Amplitud\n",
    "    err_pp      = results['err_pp']  # Error amplitud\n",
    "    Delay_fs_TT = results['Delay']   # Time delay\n",
    "\n",
    "    plt.figure()\n",
    "    plt.errorbar(Delay_fs_TT, pp_TT, err_pp, \n",
    "                  lw=1,color='red', markersize=0,capsize=1,\n",
    "                  ecolor='red',elinewidth=1,label=label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae1e9d4-37ed-43e5-adf2-2c8538d350e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c50c92f-9701-4709-b16b-63ca4842f644",
   "metadata": {},
   "source": [
    "### Model's functions (Multiexponential decay) $I(t) = \\sum^{n}_{i} A_i(t)\\cdot e^{-t/\\tau_i}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d28f2ee-7f94-4efc-9a13-f8ca4f36eae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convolved_exp(t, t0, tau, w):\n",
    "    t = np.asarray(t)\n",
    "    tau = np.maximum(tau, 1e-3)  \n",
    "    w   = np.maximum(w, 1e-3)    \n",
    "\n",
    "    arg1 = (w**2 - 2*tau*(t - t0)) / (2*tau**2)\n",
    "    arg2 = (w**2 - tau*(t - t0)) / (np.sqrt(2)*w*tau)\n",
    "\n",
    "    # Avoid overflow\n",
    "    arg1 = np.clip(arg1, -700, 700)  \n",
    "    arg2 = np.clip(arg2, -1e2, 1e2)  \n",
    "\n",
    "    res = 0.5 * np.exp(arg1) * (1 - _special.erf(arg2))\n",
    "    res = np.nan_to_num(res, nan=0.0, posinf=0.0, neginf=0.0)  # Change NaN or inf to 0\n",
    "    return res\n",
    "def model_1d(x, t, numExp, t0_choice='No'):\n",
    "    t = np.asarray(t)\n",
    "    F = np.zeros_like(t, dtype=float)\n",
    "    if t0_choice == 'No':\n",
    "        w = x[0]\n",
    "        t0 = x[1]\n",
    "        taus = x[2:2+numExp]\n",
    "        As = x[2+numExp:2+numExp+numExp]\n",
    "        for n in range(numExp):\n",
    "            F += As[n] * convolved_exp(t, t0, taus[n], w)\n",
    "    elif t0_choice == 'Fix0':\n",
    "        w = x[0]\n",
    "        taus = x[1:1+numExp]\n",
    "        As = x[1+numExp:1+numExp+numExp]\n",
    "        t0 = 0.0\n",
    "        for n in range(numExp):\n",
    "            F += As[n] * convolved_exp(t, t0, taus[n], w)\n",
    "    else:\n",
    "        raise ValueError(\"t0_choice debe ser 'No' o 'Fix0'\")\n",
    "    return F\n",
    "\n",
    "def residuals_1d(x, t, y, numExp, t0_choice='No'):\n",
    "    return model_1d(x, t, numExp, t0_choice) - y\n",
    "\n",
    "def fit_1d(t, y, numExp=3, t0_choice='No', ini=None, bounds=None, verbose=1):\n",
    "    if ini is None:\n",
    "        if t0_choice == 'No':\n",
    "            w0 = 0.2 * (t.max() - t.min()) if (t.max() - t.min())>0 else 0.1\n",
    "            t0_0 = 0.0\n",
    "            taus0 = np.array([0.5 * (3**n) for n in range(numExp)])\n",
    "            As0 = np.array([(np.max(y)-np.min(y))/numExp * (0.5 if n%2==0 else 1.0) for n in range(numExp)])\n",
    "            ini = np.concatenate(([w0, t0_0], taus0, As0))\n",
    "        else:\n",
    "            w0 = 0.2 * (t.max() - t.min()) if (t.max() - t.min())>0 else 0.1\n",
    "            taus0 = np.array([0.5 * (3**n) for n in range(numExp)])\n",
    "            As0 = np.array([(np.max(y)-np.min(y))/numExp * (0.5 if n%2==0 else 1.0) for n in range(numExp)])\n",
    "            ini = np.concatenate(([w0], taus0, As0))\n",
    "\n",
    "    if bounds is None:\n",
    "        if t0_choice == 'No':\n",
    "            lower = np.concatenate(([1e-6, t.min()-abs(t.min())*10], np.full(numExp, 1e-6), np.full(numExp, -np.inf)))\n",
    "            upper = np.concatenate(([ (t.max()-t.min())*10 if (t.max()-t.min())>0 else 10, t.max()+abs(t.max())*10], np.full(numExp, 1e12), np.full(numExp, np.inf)))\n",
    "        else:\n",
    "            lower = np.concatenate(([1e-6], np.full(numExp, 1e-6), np.full(numExp, -np.inf)))\n",
    "            upper = np.concatenate(([ (t.max()-t.min())*10 if (t.max()-t.min())>0 else 10], np.full(numExp, 1e12), np.full(numExp, np.inf)))\n",
    "        bounds = (lower, upper)\n",
    "\n",
    "    res = least_squares(residuals_1d, ini, args=(t, y, numExp, t0_choice), bounds=bounds, verbose=verbose, jac='2-point')\n",
    "\n",
    "    J = res.jac\n",
    "    try:\n",
    "        cov = np.linalg.inv(J.T @ J)\n",
    "        dof = max(1, (len(y) - len(res.x)))\n",
    "        s_sq = np.sum(res.fun**2) / dof\n",
    "        cov = cov * s_sq\n",
    "    except np.linalg.LinAlgError:\n",
    "        cov = np.zeros((len(res.x), len(res.x)))\n",
    "    return res, res.x, cov\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7290bd3-895d-46db-aa58-9a6102e8ebe6",
   "metadata": {},
   "source": [
    "### Data Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cf0a2f-974d-4590-96ed-5d25f056d4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "data1 = pd.read_csv(file_path, delimiter='\\t', header=None,skiprows=1) #Cambiar esto con los archivos del xfel\n",
    "t = data1[0].values.astype(float)\n",
    "y = data1[1].values.astype(float)\n",
    "\n",
    "# Erase infs & NaN\n",
    "mask = np.isfinite(t) & np.isfinite(y)\n",
    "t, y = t[mask], y[mask]\n",
    "order = np.argsort(t)\n",
    "t, y = t[order], y[order]\n",
    "\n",
    "# Normalization\n",
    "baseline = np.mean(y[:10])\n",
    "y_raw = y.copy()\n",
    "y = y - baseline\n",
    "scale = np.max(np.abs(y))\n",
    "y = y / scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdcd825-cb74-47b2-a02e-7ec946d578bf",
   "metadata": {},
   "source": [
    "### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ad9257e-9ee9-41f7-9485-f052036ed700",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m ini \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m20.0\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.3\u001b[39m])\n\u001b[1;32m      5\u001b[0m lower \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1e-6\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5.0\u001b[39m, \u001b[38;5;241m1e-6\u001b[39m, \u001b[38;5;241m1e-6\u001b[39m, \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf]\n\u001b[0;32m----> 6\u001b[0m upper \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m10.0\u001b[39m, np\u001b[38;5;241m.\u001b[39mmax(\u001b[43mt\u001b[49m), \u001b[38;5;241m1e6\u001b[39m, \u001b[38;5;241m1e6\u001b[39m, np\u001b[38;5;241m.\u001b[39minf, np\u001b[38;5;241m.\u001b[39minf]\n\u001b[1;32m      7\u001b[0m bounds \u001b[38;5;241m=\u001b[39m (lower, upper)\n",
      "\u001b[0;31mNameError\u001b[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "# Fit to 2 exponential model\n",
    "numExp = 2\n",
    "t0_choice = 'No'\n",
    "ini = np.array([1.0, \n",
    "                0.5,\n",
    "                1.0, 20.0,\n",
    "                0.5, -0.3])\n",
    "lower = [1e-6, -5.0, 1e-6, 1e-6, -np.inf, -np.inf]\n",
    "upper = [10.0, np.max(t), 1e6, 1e6, np.inf, np.inf]\n",
    "bounds = (lower, upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6c0e7d-e807-41fb-9686-34a3a94b6e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit to 3 exponential model\n",
    "numExp = 3\n",
    "t0_choice = 'No'    \n",
    "ini = np.array([\n",
    "    0.5,      # w\n",
    "    0.0,      # t0\n",
    "    0.5, 2.0, 10.0,   # taus (3)\n",
    "    1.0, -0.3, 0.2    # Amps (3)\n",
    "])\n",
    "\n",
    "lower = (\n",
    "    [1e-6, -5.0] +      # w, t0\n",
    "    [1e-6]*3 +          # tau1..tau3\n",
    "    [-np.inf]*3         # A1..A3\n",
    ")\n",
    "\n",
    "upper = (\n",
    "    [10.0, np.max(t)] +  # w, t0\n",
    "    [1e6]*3 +            # tau1..tau3\n",
    "    [np.inf]*3           # A1..A3\n",
    ")\n",
    "\n",
    "bounds = (lower, upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b9340d-3d15-49e0-ad38-7f19e554e95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit to 4 exponential model\n",
    "numExp = 4\n",
    "t0_choice = 'No'    \n",
    "\n",
    "# Inicialización de parámetros: [w, t0, tau1..tau4, A1..A4]\n",
    "ini = np.array([\n",
    "    0.5,      # w\n",
    "    0.0,      # t0\n",
    "    0.5, 2.0, 10.0, 25.0,   # taus (4)\n",
    "    1.0, -0.3, 0.2, 0.5     # Amps (4)\n",
    "])\n",
    "\n",
    "# Límites inferiores\n",
    "lower = (\n",
    "    [1e-6, -5.0] +      # w, t0\n",
    "    [1e-6]*4 +          # tau1..tau4\n",
    "    [-np.inf]*4         # A1..A4\n",
    ")\n",
    "\n",
    "# Límites superiores\n",
    "upper = (\n",
    "    [10.0, np.max(t)] +  # w, t0\n",
    "    [1e6]*4 +            # tau1..tau4\n",
    "    [np.inf]*4           # A1..A4\n",
    ")\n",
    "\n",
    "bounds = (lower, upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b783b2c-eaa8-4f22-9f1c-16fb54da7c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "res, xopt, cov = fit_1d(t, y, numExp=numExp, t0_choice=t0_choice, ini=ini, bounds=bounds, verbose=1)\n",
    "\n",
    "#  Parameters\n",
    "w_opt = xopt[0]\n",
    "t0_opt = xopt[1]\n",
    "taus_opt = xopt[2:2+numExp]\n",
    "As_opt = xopt[2+numExp:2+numExp+numExp]\n",
    "errs = np.sqrt(np.abs(np.diag(cov))) if cov.size else np.zeros_like(xopt)\n",
    "\n",
    "print(\"\\n=== Resultados ajustados ===\")\n",
    "print(f\"w  = {w_opt:.4f} ± {errs[0]:.4f}\")\n",
    "print(f\"t0 = {t0_opt:.4f} ± {errs[1]:.4f}\")\n",
    "for n in range(numExp):\n",
    "    print(f\"tau{n+1} = {taus_opt[n]:.4f} ± {errs[2+n]:.4f}\")\n",
    "    print(f\"A{n+1}   = {As_opt[n]:.6f} ± {errs[2+numExp+n]:.6f}\")\n",
    "\n",
    "# Model fit\n",
    "y_fit_norm = model_1d(xopt, t, numExp=numExp, t0_choice=t0_choice)\n",
    "y_fit = y_fit_norm * scale + baseline\n",
    "\n",
    "# Plots\n",
    "plt.figure(figsize=(8,5),constrained_layout=True)\n",
    "plt.plot(t, y_raw, 'b', label='Data', alpha=0.8)\n",
    "plt.plot(t, y_fit, 'k--', lw=2, label='Fit (resc.)')\n",
    "plt.xlabel('Time (ps)')\n",
    "plt.ylabel('DA (Counts)')\n",
    "plt.title('Multiexponential decay fit')\n",
    "plt.xlim(-1, 20)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa543ef-49da-4e05-9bed-8dc3a4dc40e9",
   "metadata": {},
   "source": [
    "### Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f43674-90d5-47ac-b4d3-41ad97c45e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results in the same file of the .csv/.dat/.txt\n",
    "input_name = os.path.basename(file_path)\n",
    "output_name = os.path.splitext(input_name)[0] + \"_fit.csv\"\n",
    "output_path = os.path.join(os.path.dirname(file_path), output_name)\n",
    "\n",
    "df_out = pd.DataFrame({\n",
    "    'Tiempo_ps': t,\n",
    "    'Datos_originales': y_raw,\n",
    "    'Modelo_ajuste': y_fit\n",
    "})\n",
    "df_out.to_csv(output_path, index=False, float_format='%.6f')\n",
    "print(f\"\\n File saved in:\\n{output_path}\")\n",
    "\n",
    "# Save the fit parameters in the same file\n",
    "output_params_name = os.path.splitext(input_name)[0] + \"_taus_amplitudes.txt\"\n",
    "output_params_path = os.path.join(os.path.dirname(file_path), output_params_name)\n",
    "As_opt_real = As_opt * scale\n",
    "\n",
    "with open(output_params_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"=== Tau and Amplitudes fit (or.units) ===\\n\\n\") #or = original units\n",
    "    f.write(\"{:<10} {:>15} {:>15}\\n\".format(\"Parameter\", \"Value\", \"Error\"))\n",
    "    f.write(\"-\"*40 + \"\\n\")\n",
    "    for n in range(numExp):\n",
    "        f.write(\"{:<10} {:>15.6f} {:>15.6f}\\n\".format(f\"tau{n+1}\", taus_opt[n], errs[2+n]))\n",
    "    for n in range(numExp):\n",
    "        f.write(\"{:<10} {:>15.6f} {:>15.6f}\\n\".format(f\"A{n+1}\", As_opt_real[n], errs[2+numExp+n]*scale))\n",
    "\n",
    "print(f\"\\n τ and Amplitudes saved in:\\n{output_params_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:alvra-analysis-p22591]",
   "language": "python",
   "name": "conda-env-alvra-analysis-p22591-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
